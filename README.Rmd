---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# ernest: Nested Sampling in R

<!-- badges: start -->
<!-- badges: end -->

ernest provides a toolkit for performing the nested sampling algorithm to estimate the marginal likelihood (i.e., evidence) and posterior distributions of statistical models. To this end, ernest aims to accomplish two different goals:

1. If you're unfamiliar with nested sampling, ernest and its documentation will allow you to learn how nested sampling works and how you might incorporate it within your analyses.
2. If you're already familiar with nested sampling, ernest provides a powerful and reliable implementation of the algorithm and different likelihood-restricted prior samplers, allowing you to complete and analyse runs with existing tools offered by [ggplot](https://CRAN.R-project.org/package=ggplot2) and [posterior](https://CRAN.R-project.org/package=posterior).

## Installation

You can install the development version of ernest from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("kylesnap/ernest")
```

## Status

`ernest` is still quite experimental, and additional features are intended to be added in the future. While we hope to avoid them, this does mean that certain components of ernest may be subject to breaking changes. 

If you encounter any issues or have any suggestions, please feel free to open an issue.

## Acknowledgements

The nested sampling algorithm was first developed and introduced by J. Skilling across two major papers:

- Skilling, J. (2004). Nested sampling. In R. Fischer and R. Preuss and U. V. Toussaint (Eds.), _Bayesian Inference and Maximum Entropy Methods in Science and Engineering_ (pp. 395-405). AIP. [10.1063/1.1835238](https://doi.org/10.1063/1.1835238)
- Skilling, J. (2006). Nested sampling for general Bayesian computation. _Bayesian Analysis_, 1(4), 833-859. [10.1214/06-BA127](https://doi.org/10.1214/06-BA127)

ernest's design takes much inspiration from from the well-documented [dynesty](https://dynesty.readthedocs.io/en/stable/index.html) package:

- Speagle, J. S. (2020). DYNESTY: A dynamic nested sampling package for estimating Bayesian posteriors and evidences. _Monthly Notices of the Royal Astronomical Society_, 493(3), 3132-3158. [10.1093/mnras/staa278](https://doi.org/10.1093/mnras/staa278)
- Koposov, S., Speagle, J. S., Barbary, K., Ashton, G., Bennett, E., Buchner, J., Scheffler, C., Cook, B., Talbot, C., Guillochon, J., Cubillos, P., Ramos, A. A., Dartiailh, M., Ilya., Tollerud, E., Lang, D., Johnson, B., jtmendel, Higson, E., ... Goldstein, D. (2021). _dynesty_ (Version 1.1.1.) [Python package]. [10.5281/zenodo.4543937](https://doi.org/10.5281/zenodo.4543937)

In addition, the [nestle](https://github.com/kbarbary/nestle/tree/master) python package and an article from J. Buchner provide consistent and clear terminology to describe and organize components of the nested sampling algorithm:

- Buchner, J. (2023). Nested sampling methods. _Statistics Surveys_, 17, 169-215. [10.1214/23-SS144](https://doi.org/10.1214/23-SS144)
