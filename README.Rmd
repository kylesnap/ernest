---
output: github_document
bibliography: vignettes/references.bib
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# A Toolkit for Nested Sampling

```{r srr, eval = FALSE, echo = FALSE}
#' SRR STATS BLOCK
#' 
#' @srrstats {G1.0, G1.1} Contains primary references and list of previous NS softwares. Also states that ernest is the first R package providing a toolkit for implementing NS.
#' @srrstats {BS1.2, BS1.2a} Introduces how priors are specified within ernest.
```

<!-- badges: start -->

[![R-CMD-check](https://github.com/kylesnap/ernest/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/kylesnap/ernest/actions/workflows/R-CMD-check.yaml) [![codecov](https://codecov.io/gh/kylesnap/ernest/branch/ropensci_submission/graph/badge.svg?token=6HL8L046Y7)](https://codecov.io/gh/kylesnap/ernest)

<!-- badges: end -->

**ernest** is a comprehensive toolkit for [nested sampling](https://en.wikipedia.org/wiki/Nested_sampling_algorithm) (NS), an algorithm for estimating a statistical model's Bayesian evidence and posterior distribution. It provides S3 objects and methods that make nested sampling accessible, flexible, and robust within the R environment.

## Installation

Install the development version of ernest from [GitHub](https://github.com/kylesnap/ernest) with:

``` r
# install.packages("devtools")
devtools::install_github("kylesnap/ernest")
```

## Why use ernest?

In Bayesian inference, evidence ($\mathcal{Z}$, also called the [marginal likelihood](https://en.wikipedia.org/wiki/Marginal_likelihood)) is the probability of observing data $D$ under a proposed model $M$. This is obtained by integrating the model's likelihood over the prior distribution of $M$'s parameters. $\mathcal{Z}$ provides a parameter-independent way to assess the plausibility of $D$ given $M$, and is key for Bayesian model comparison through methods such as [Bayes factors](https://en.wikipedia.org/wiki/Bayes_factor).

Calculating $\mathcal{Z}$ is challenging, as it requires evaluating a high-dimensional integral over the parameter space. Nested sampling estimates this integral by dividing the space into a series of small volumes. It starts by drawing points from the prior and ranking them by likelihood. The least likely points are discarded and replaced with new samples from more restricted likelihood regions, gradually compressing the search space. Each round of discarding shrinks the explored volume in a predictable way, helping to approximate the integral.

This approach to estimating $Z$ offers several advantages over methods like Markov chain Monte CarloÂ (MCMC):

-   **Robustness**: NS handles complex likelihood surfaces that would otherwise be difficult to traverse, such as those with multiple modes or discontinuities.
-   **Posterior inference**: After a run, discarded samples can be weighted to approximate the model's posterior distribution.
-   **Natural stopping criterion**: NS can estimate the amount of evidence left within the unexplored prior volume, and can stop sampling once this amount gets trivially small.
-   **Tractable uncertainty estimates**: The shrinkage at each iteration follows a uniform order statistic, so uncertainty can be simulated using the results from a single run.

ernest's implementation of NS offers R users several benefits:

-   **Native R implementation**: John Skilling's [@skilling2004, @skilling2006] NS algorithm is implemented in R, with no Python or Fortran dependencies. (C++ is used to implement the included likelihood samplers to improve run-time efficiency).
-   **Type- and size-safety**: ernest helps ensure that the user provides likelihood functions and prior specifications meet the requirements of the NS algorithm.
-   **Familiar methods**: Sampler specifications and results are stored in S3 objects. Start or continue an NS run with `generate()`, review results with `summary()`, and simulate estimation error with `calculate()`.
-   **Powerful visualizations**: Plot evidence estimates and analyse posterior distributions using [ggplot2](https://ggplot2.tidyverse.org) and [posterior](https://mc-stan.org/posterior/).

## Quick Example

This example demonstrates a basic workflow: define a prior, specify a likelihood, run nested sampling, and summarise results.

``` r
library(ernest)

# Define a prior (i.i.d. multivariate uniform)
prior <- create_uniform_prior(lower = -10, upper = 10, names = c("x", "y", "z"))

# Define a log-likelihood function (multivariate normal)
mu <- c(0, 0, 0)
Sigma <- diag(1, 3)
Sigma[Sigma == 0] <- 0.95
loglike <- create_likelihood(
  rowwise_fn = LaplacesDemon::dmvn,
  mu = !!mu,
  Sigma = !!Sigma,
  log = TRUE
)

# Set up and run the sampler
sampler <- ernest_sampler(
  log_lik = loglike,
  prior = prior,
  n_points = 500
)
run <- generate(sampler)

# Summarise and visualise results
summary(run)
plot(run)
visualize(run, type = "trace")
```

For advanced usage, including custom priors and hierarchical models, see the package vignettes.

## Learn More

-   **About NS**: `vignette("nested-sampling-with-ernest")`, @skilling2004, @skilling2006, and @buchner2023.
-   **How to use ernest**: `vignette("more-ernest-runs.Rmd")`.

## Prior Work

NS has been implemented in many languages; some offer R interfaces. This non-exhaustive list of popular NS implementations is adapted from @fowlie2021:

| Package | Citation | Language(s) |
|:---------------------|:--------------------:|:--------------------------:|
| [nestle](https://github.com/kbarbary/nestle/tree/master) | @barbary2015 | Python |
| [dynesty](https://github.com/joshspeagle/dynesty) | @speagle2020 | Python |
| [DIAMONDS](https://github.com/EnricoCorsaro/DIAMONDS/) | @corsaro2014 | C++ |
| [MultiNest](https://github.com/JohannesBuchner/MultiNest) | @feroz2009 | Fortran; interfaces for C++, Python, R, and MatLab |
| [PolyChord](https://github.com/PolyChord/PolyChordLite) | @handley2015 | Fortran; interfaces for C++ and Python |
| [DNest4](https://github.com/eggplantbren/DNest4) | @brewer2018 | C++; interfaces with Python, R, and Julia |

ernest's design, API, and NS implementation are based on the nestle package, with further inspiration from dynesty.

The [nestcheck](https://github.com/ejhigson/nestcheck/tree/master) Python package provides routines for error estimation and diagnostic plotting with nested sampling runs [@higson2019]. Several of ernest's methods are based on this work.

------------------------------------------------------------------------

\emph{References}
